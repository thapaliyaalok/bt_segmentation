{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import numpy as np\n",
    "from IPython import get_ipython\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORIES = [\"no\", \"yes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(filepath):\n",
    "    IMG_SIZE = 100 \n",
    "    img_array = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)  # read in the image, convert to grayscale\n",
    "    new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize image to match model's expected sizing\n",
    "    return new_array.reshape(-1, IMG_SIZE, IMG_SIZE, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0814 10:22:28.749589 12232 deprecation.py:506] From C:\\Users\\Yugesh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0814 10:22:28.768580 12232 deprecation.py:506] From C:\\Users\\Yugesh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0814 10:22:28.770578 12232 deprecation.py:506] From C:\\Users\\Yugesh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0814 10:22:29.412289 12232 deprecation.py:323] From C:\\Users\\Yugesh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(\"Trained.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = ('C:/Users/Yugesh/Dataset/Test/ no.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict([prepare(img)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no\n"
     ]
    }
   ],
   "source": [
    "prediction\n",
    "prediction[0][0]\n",
    "print(CATEGORIES[int(prediction[0][0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO TUMOR DETECTED\n"
     ]
    }
   ],
   "source": [
    "prediction\n",
    "if prediction == [[1.]]:\n",
    "    print(\"TUMOR DETECTED\")\n",
    "    orig_img = cv2.imread(img,1) # 1 indicates color image\n",
    "    # OpenCV uses BGR while Matplotlib uses RGB format\n",
    "    # Display the color image with matplotlib\n",
    "    plt.imshow(cv2.cvtColor(orig_img, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')\n",
    "    print=(\"Input MRI\")\n",
    "    plt.show()\n",
    "    gray_img = cv2.cvtColor( orig_img, cv2.COLOR_BGR2GRAY ) \n",
    "    plt.imshow(gray_img,cmap='gray')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    #median filtering to remove grainy noise\n",
    "    median_filtered = cv2.medianBlur(gray_img, 5)\n",
    "    plt.imshow(median_filtered,cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    #edge detection using sobel\n",
    "    Gx= np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\n",
    "    Gy = np.array([[1, 2, 1], [0, 0, 0], [-1, -2, -1]])\n",
    "    img_sobelx = cv2.Sobel(median_filtered,cv2.CV_8U,1,0,ksize=3)\n",
    "    img_sobely = cv2.Sobel(median_filtered,cv2.CV_8U,0,1,ksize=3)\n",
    "    \n",
    "    #del f = Gx + Gy\n",
    "    # Adding mask to the image\n",
    "    img_sobel = img_sobelx + img_sobely+gray_img\n",
    "    plt.imshow(img_sobel,cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    # Set threshold and maxValue\n",
    "    threshold = 50\n",
    "    maxValue = 255\n",
    " \n",
    "    # Threshold the pixel values\n",
    "    th, thresh = cv2.threshold(img_sobel, threshold, maxValue, cv2.THRESH_OTSU)\n",
    "    plt.imshow(thresh,cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    # To remove any small white noises in the image using morphological opening. \n",
    "    # To determine foreground and background\n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    opening = cv2.morphologyEx(thresh,cv2.MORPH_OPEN,kernel, iterations = 2)\n",
    "\n",
    "    plt.imshow(opening,cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    # Black region shows sure background area\n",
    "    # Dilation increases object boundary to background.\n",
    "    sure_bg = cv2.dilate(opening,kernel,iterations=3)\n",
    "\n",
    "    plt.imshow(sure_bg,cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    #  White region shows sure foreground area\n",
    "    dist_transform = cv2.distanceTransform(opening,cv2.DIST_L2,5)\n",
    "    ret, sure_fg = cv2.threshold(dist_transform,0.7*dist_transform.max(),255,0)\n",
    "\n",
    "    plt.imshow(sure_fg,cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    # Identifying regions where we don't know whether foreground and background\n",
    "    # Watershed algorithm\n",
    "    sure_fg = np.uint8(sure_fg)\n",
    "    unknown = cv2.subtract(sure_bg,sure_fg)\n",
    "\n",
    "    plt.imshow(unknown,cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    #Watershed Segmentation\n",
    "    contours, hierarchy = cv2.findContours(sure_fg,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Creating a numpy array for markers and converting the image to 32 bit using dtype paramter\n",
    "    marker = np.zeros((gray_img.shape[0], gray_img.shape[1]),dtype = np.int32)\n",
    "\n",
    "    marker = np.int32(sure_fg) + np.int32(sure_bg)\n",
    "    \n",
    "    # Marker Labelling\n",
    "    for id in range(len(contours)):\n",
    "        cv2.drawContours(marker,contours,id,id+2, -1)\n",
    "\n",
    "    marker = marker + 1\n",
    "\n",
    "    marker[unknown==255] = 0\n",
    "\n",
    "    copy_img = orig_img.copy()\n",
    "\n",
    "    cv2.watershed(copy_img, marker)\n",
    "\n",
    "    imgplt = plt.imshow(marker)\n",
    "\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "    \n",
    "    copy_img[marker==-1]=(0,0,255)\n",
    "    cv2.imwrite('img.jpg',copy_img)\n",
    "    plt.imshow(copy_img,cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    #Opening by erosion\n",
    "    # The basic purpose of the operation is to show only that part of the image having \n",
    "    # more intensity which has the tumor that is the part of the image forming our desired extraction.\n",
    "    kernel=cv2.getStructuringElement(cv2.MORPH_RECT,(7,7))\n",
    "    erosion = cv2.morphologyEx(median_filtered, cv2.MORPH_ERODE, kernel)\n",
    "    plt.imshow(erosion,cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    #Opening by dilation\n",
    "    dilation = cv2.morphologyEx(erosion, cv2.MORPH_DILATE, kernel)\n",
    "    plt.imshow(dilation,cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"NO TUMOR DETECTED\")\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().magic('reset -sf') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
